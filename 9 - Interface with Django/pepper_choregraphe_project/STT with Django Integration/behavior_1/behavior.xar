<?xml version="1.0" encoding="UTF-8" ?><ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3"><Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0"><bitmap>media/images/box/root.png</bitmap><script language="4"><content><![CDATA[]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /><Timeline enable="0"><BehaviorLayer name="behavior_layer1"><BehaviorKeyframe name="keyframe1" index="1"><Diagram><Box name="Set Language" id="2" localization="8" tooltip="Set the language of your robot for the current application. Your robot will speak and understand the selected language as long as your application has focus. Any following call to ALSpeechRecognition (Speech Reco. box for instance), ALTextToSpeech (Say box for instance) or ALDialog will use this language.&#x0A;&#x0A;&#x0A;&#x0A;MARC: It is always good practice to set the language for your Choregraphe projects. You are declaring to other developers that this application was developed with this language in mind. If you choose to support multiple languages, you must make sure the application is compatible with language translations." x="174" y="347"><bitmap>media/images/box/interaction/say.png</bitmap><script language="4"><content><![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        try:
            self.tts = ALProxy("ALTextToSpeech")
        except:
            self.logger.warn("ALTextToSpeech is not available, language setting cannot be applied to speech")
            self.tts = None

        try:
            self.asr = ALProxy("ALSpeechRecognition")
        except:
            self.logger.warn("ALSpeechRecognition is not available, language setting cannot be applied to recognition")
            self.asr = None

        try:
            self.dialog = ALProxy("ALDialog")
        except:
            self.logger.warn("ALDialog is not available, language setting cannot be applied to dialog")
            self.dialog = None

    def onInput_onSet(self):
        lang = self.getParameter("Language")
        try:
            if self.asr:
                self.asr.setLanguage( self.getParameter("Language") )
            if self.tts:
                self.tts.setLanguage( self.getParameter("Language") )
            if self.dialog:
                self.dialog.setLanguage( self.getParameter("Language") )
            if self.tts is None and self.asr is None and self.dialog is None:
                raise RuntimeError("Cannot set language: neither ALTextToSpeech nor ALSpeechRecognition nor ALDialog is available.")
            self.onReady()
        except:
            error = "Language " + lang + " cannot be set."
            self.logger.warn(error)
            self.onError(error)]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onSet" type="1" type_size="1" nature="1" inner="0" tooltip="The data is set when a signal is received on this input." id="2" /><Output name="onReady" type="1" type_size="1" nature="2" inner="0" tooltip="Signal sent when the data has been set." id="3" /><Output name="onError" type="3" type_size="1" nature="2" inner="0" tooltip="Error output:&#x0A;- triggered if the language asked cannot be set" id="4" /><Parameter name="Language" inherits_from_parent="0" content_type="3" value="English" default_value="English" custom_choice="1" tooltip="Set the language the robot speaks and understands." id="5"><Choice value="Arabic" /><Choice value="Brazilian" /><Choice value="Chinese" /><Choice value="Czech" /><Choice value="Danish" /><Choice value="Dutch" /><Choice value="English" /><Choice value="Finnish" /><Choice value="French" /><Choice value="German" /><Choice value="Greek" /><Choice value="Italian" /><Choice value="Japanese" /><Choice value="Korean" /><Choice value="MandarinTaiwan" /><Choice value="Norwegian" /><Choice value="Polish" /><Choice value="Portuguese" /><Choice value="Russian" /><Choice value="Spanish" /><Choice value="Swedish" /><Choice value="Turkish" /></Parameter><Resource name="Speech" type="Lock" timeout="0" /></Box><Box name="Greeting" id="3" localization="8" tooltip='MARC: This is the introductory greeting. This box is hard-coded to have Pepper say the specified text in its parameters. This is useful if you need Pepper to say something specific at specific points (triggers) in the application. For our use-case, it can be merged into the Dialog script instead.&#x0A;&#x0A;Pepper will say:&#x0A;&quot;Hello, my name is Pepper. This demo shows how developers can connect to Django to extend my capabilities!&quot;' x="653" y="323"><bitmap>media/images/box/interaction/say.png</bitmap><script language="4"><content><![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += self.getParameter("Text")
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" /><Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" /><Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" /><Parameter name="Text" inherits_from_parent="0" content_type="5" value="Hello, my name is Pepper. This demo shows how developers can connect to Django to extend my capabilities!" default_value="" tooltip="The text you want to say. Don&apos;t forget to translate it!" id="7" /></Box><Box name="Autonomous Abilities" id="1" localization="8" tooltip="Autonomous Abilities exists to keep the robot alive at all times. But this box allows you to disable all or parts of the Autonomous Abilities (Autonomous Blinking, Background Movement, Basic Awareness, Listening Movement, Speaking Movement).&#x0A;&#x0A;&#x0A;&#x0A;MARC: Let&apos;s disable all of Pepper&apos;s autonomous abilities to isolate and focus on the Django integration." x="332" y="404"><bitmap>media/images/box/auto-abilities.png</bitmap><script language="4"><content><![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.autonomouslife = ALProxy("ALAutonomousLife")

    def onUnload(self):
        pass

    def onInput_onStart(self):
        self.enableAnAbility("AutonomousBlinking")
        self.enableAnAbility("BackgroundMovement")
        self.enableAnAbility("BasicAwareness")
        self.enableAnAbility("ListeningMovement")
        self.enableAnAbility("SpeakingMovement")
        self.onDone() # activate output of the box

    def enableAnAbility(self, name):
        self.autonomouslife.setAutonomousAbilityEnabled(name, self.getParameter(name))]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" /><Parameter name="AutonomousBlinking" inherits_from_parent="0" content_type="0" value="0" default_value="1" tooltip="Enables the robot to make its eye leds blink when it sees someone and when it is interacting." id="4" /><Parameter name="BackgroundMovement" inherits_from_parent="0" content_type="0" value="0" default_value="1" tooltip="Defines which slight movements the robot does autonomously when its limbs are not moving." id="5" /><Parameter name="BasicAwareness" inherits_from_parent="0" content_type="0" value="0" default_value="1" tooltip="Allow to make the robot establish and keep eye contact with people." id="6" /><Parameter name="ListeningMovement" inherits_from_parent="0" content_type="0" value="0" default_value="1" tooltip="Enables some slight movements showing that the robot is listening." id="7" /><Parameter name="SpeakingMovement" inherits_from_parent="0" content_type="0" value="0" default_value="1" tooltip="Enables to start autonomously movements during the speech of the robot." id="8" /></Box><Box name="Start?" id="4" localization="8" tooltip='MARC: This Dialog script is where the developer has the chance to branch control based on the user&apos;s response. A simple Dialog script may consist of a response for &quot;Yes&quot; or &quot;No&quot; based on this project&apos;s logic.' x="589" y="517"><dialogFile>../Reply/Reply.dlg</dialogFile><bitmap>media/images/box/box-dialog.png</bitmap><script language="4"><content><![CDATA[]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Input name="onAgain" type="1" type_size="1" nature="2" inner="0" tooltip="Starts the cycle again." id="4" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="" id="5" /><Output name="onStartRecording" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when the user decides to start the demo." id="6" /><Resource name="Speech" type="Lock" timeout="0" /><Resource name="Speech recognition" type="Lock" timeout="0" /></Box><Box name="Single Dialog Script" id="5" localization="8" tooltip="To comment your behavior. Enter the text here and move the box where you like&#x0A;to add the comment.&#x0A;&#x0A;Note: This box is not functional and has no effect on the behavior." plugin="textedit_plugin" x="750" y="296"><bitmap>media/images/box/box-script.png</bitmap><script language="4"><content><![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("Rather than having a series of \"Say\" Choregraphe boxes. It is easier to merge these into one Dialog box as shown below.")]]></content></script><pluginContent><text><![CDATA[Rather than having a series of "Say" Choregraphe boxes. It is easier to merge these into one Dialog box as shown below.]]></text></pluginContent><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" /></Box><Box name="Basic Setup" id="6" localization="8" tooltip="To comment your behavior. Enter the text here and move the box where you like&#x0A;to add the comment.&#x0A;&#x0A;Note: This box is not functional and has no effect on the behavior." plugin="textedit_plugin" x="96" y="500"><bitmap>media/images/box/box-script.png</bitmap><script language="4"><content><![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("Set project\'s expected language and disable all autonomous abilities (in order to focus on the Djang integration) above.")]]></content></script><pluginContent><text><![CDATA[Set project's expected language and disable all autonomous abilities (in order to focus on the Djang integration) above.]]></text></pluginContent><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" /></Box><Box name="Record Sound" id="8" localization="8" tooltip='Record a sound on the robot. You can choose to record only with one&#x0A;microphone (the front head microphone) in ogg format, or with four microphones&#x0A;(front, sides and rear head microphones) in wav format.&#x0A;&#x0A;If &quot;Temporary storage&quot; isn&apos;t checked, the output sound file is located in &quot;~/recordings/microphones/&lt;File name&gt;&quot;.&#x0A;Else, it is located in a temporary directory&#x0A;&#x0A;The onStopped output is stimulated at the end of the recording and contains the absolute path to the output sound file&#x0A;&#x0A;V1.1.0&#x0A;' x="772" y="582"><bitmap>media/images/box/interaction/rec_sound.png</bitmap><script language="4"><content><![CDATA[]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Launches the recording of the sound." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stops the recording of the sound." id="3" /><Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Returns the absolute path of the output sound file at the end of the recording" id="4" /><Parameter name="File name" inherits_from_parent="0" content_type="3" value="recording" default_value="recording" custom_choice="0" tooltip="Name of the destination file without its extension." id="5" /><Parameter name="Microphones used" inherits_from_parent="0" content_type="3" value="Front head microphone only (.ogg)" default_value="Front, sides and rear head microphones (.wav)" custom_choice="0" tooltip="Microphones used to record the sound.&#x0A;&#x0A;Note: If you use only the front head microphone the file will be saved in ogg format. If you use the&#x0A;front, sides and rear head microphones it will be saved in wav format." id="6"><Choice value="Front head microphone only (.ogg)" /><Choice value="Front, sides and rear head microphones (.wav)" /></Parameter><Parameter name="Temporary storage" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Choose if the file should be stored as a temporary file so it is removed as soon&#x0A;as the behavior is unloaded.&#x0A;&#x0A;When this option is disabled the file is stored in ~/recordings/microphones. You can&#x0A;then get it on your computer using the menu Connection/File transfer.&#x0A;&#x0A;When this option is enabled the file is stored in the temporary folder of the behavior." id="7" /><Parameter name="Timeout (s)" inherits_from_parent="0" content_type="2" value="10" default_value="5" min="0.1" max="60" tooltip="Duration of the recording in seconds." id="8" /><Timeline enable="0"><BehaviorLayer name="behavior_layer1"><BehaviorKeyframe name="keyframe1" index="1"><Diagram><Box name="Rec. Sound File" id="4" localization="8" tooltip="Record a sound on the robot. You can choose to record only with one&#x0A;microphone (the front head microphone) in ogg format, or with four microphones&#x0A;(front, sides and rear head&#x0A;microphones) in wav format." x="562" y="100"><bitmap>media/images/box/interaction/rec_sound.png</bitmap><script language="4"><content><![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        try:
            self.ad = ALProxy("ALAudioDevice")
        except Exception as e:
            self.ad = None
            self.logger.error(e)
        self.filepath = ""

    def onLoad(self):
        self.bIsRecording = False
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False
        if( self.bIsRecording ):
            self.ad.stopMicrophonesRecording()
            self.bIsRecording = False

    def onInput_onStart(self, p):
        if(self.bIsRunning):
            return
        self.bIsRunning = True
        sExtension = self.toExtension( self.getParameter("Microphones used") )
        self.filepath = p + sExtension
        if self.ad:
            self.ad.startMicrophonesRecording( self.filepath )
            self.bIsRecording = True
        else:
            self.logger.warning("No sound recorded")

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped(self.filepath)

    def toExtension(self, sMicrophones):
        if( sMicrophones == "Front head microphone only (.ogg)" ):
            return ".ogg"
        else:
            return ".wav"]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Launches the recording of the sound. The data received on this input must be the&#x0A;filename of the sound." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stops the recording of the sound." id="3" /><Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Returns the absolute path of the output sound file at the end of the recording" id="4" /><Parameter name="Microphones used" inherits_from_parent="1" content_type="3" value="Front, sides and rear head microphones (.wav)" default_value="Front, sides and rear head microphones (.wav)" custom_choice="0" tooltip="Microphones used to record the sound.&#x0A;&#x0A;Note: If you use only the front head microphone the file will be saved in ogg format. If you use the&#x0A;front, sides and rear head microphones it will be saved in wav format." id="5"><Choice value="Front head microphone only (.ogg)" /><Choice value="Front, sides and rear head microphones (.wav)" /></Parameter></Box><Box name="Get File Name" id="10" localization="8" tooltip="Use this box to choose an attached file in its parameters. The filename will be sent on&#x0A;the output when the input is stimulated." x="234" y="95"><bitmap>media/images/box/folder.png</bitmap><script language="4"><content><![CDATA[import os
class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        pass

    def onInput_onStart(self):
        if( self.getParameter("Temporary storage") ):
            import tempfile
            path = tempfile.mkdtemp() + "/"
        else:
            path = os.path.expanduser('~') + "/recordings/microphones/"
        self.onStopped( path + self.getParameter("File name") )]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the filepath on the output." id="2" /><Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The filepath of the selected resource file." id="3" /><Parameter name="File name" inherits_from_parent="1" content_type="3" value="recording" default_value="" custom_choice="0" tooltip="Name of the file." id="4" /><Parameter name="Temporary storage" inherits_from_parent="1" content_type="0" value="1" default_value="1" tooltip="Choose if the file should be stored as a temporary file so it is removed as soon&#x0A;as the behavior is unloaded.&#x0A;&#x0A;When this option is enabled the file is stored in ~/.cache/currentChoregrapheBehavior&#x0A;or in ~/.cache/&lt;project_name&gt; when you play the behavior from the&#x0A;behavior manager.&#x0A;&#x0A;When it is disabled the file is stored in ~/recordedSounds. You can&#x0A;then get it on your computer using the menu Connection/File transfer." id="5" /></Box><Box name="Wait" id="6" localization="8" tooltip="Wait a moment before sending a signal on the output. &#x0A;Can be stopped anytime. &#x0A;Stimulating the input again before output is activated restarts the waiting period.&#x0A;" x="392" y="166"><bitmap>media/images/box/wait.png</bitmap><script language="4"><content><![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.waiting = None

    def onUnload(self):
        self.cancelWaiting()

    def triggerOutput(self):
        self.timerOutput()

    def cancelWaiting(self):
        if self.waiting:
            self.waiting.cancel()
        self.waiting = None

    def onInput_onStart(self):
        self.cancelWaiting()
        import qi
        self.waiting = qi.async(self.triggerOutput, delay=int(self.getParameter("Timeout (s)") * 1000 * 1000))

    def onInput_onStop(self):
        if self.getParameter("Trigger timerOutput if cancelled") and self.waiting and self.waiting.isRunning():
            self.timerOutput()
        self.onUnload()]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Start the Wait box with the configured timeout value." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stop the wait and stimulate the output." id="3" /><Output name="timerOutput" type="1" type_size="1" nature="1" inner="0" tooltip="Send a bang once time set in parameters is elapsed, or if the box is stopped and the appropriate parameter is set." id="4" /><Parameter name="Timeout (s)" inherits_from_parent="1" content_type="2" value="5" default_value="5" min="0.1" max="60" tooltip="Duration the box waits before stimulating the output." id="5" /><Parameter name="Trigger timerOutput if cancelled" inherits_from_parent="0" content_type="0" value="0" default_value="1" tooltip="If the box is currently waiting and cancelled, output will be stimulated." id="6" /></Box><Link inputowner="0" indexofinput="4" outputowner="4" indexofoutput="4" /><Link inputowner="10" indexofinput="2" outputowner="0" indexofoutput="2" /><Link inputowner="4" indexofinput="2" outputowner="10" indexofoutput="3" /><Link inputowner="6" indexofinput="2" outputowner="10" indexofoutput="3" /><Link inputowner="4" indexofinput="3" outputowner="6" indexofoutput="4" /></Diagram></BehaviorKeyframe></BehaviorLayer></Timeline><Resource name="Audio recorder" type="Lock" timeout="0" /></Box><Box name="Google Cloud STT" id="7" localization="8" tooltip="MARC: A Python box dedicated to handling requests and responses from the Google Cloud speech-to-text API. Note that if you are attempting to run this application, you will need to modify the API_KEY attribute to an existing API key." x="963" y="789"><bitmap>media/images/box/box-python-script.png</bitmap><script language="4"><content><![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.tts = ALProxy('ALTextToSpeech')

    def onLoad(self):
        pass

    def onUnload(self):
        pass

    def onInput_onStart(self, file_path):
        import json
        import base64
        import requests

        # WARNING: I hard-coded the API key into the endpoint;
        # when I disable the API (since it could cost me money), this endpoint will die
        API_KEY = 'AIzaSyA5e_RGNEJ8jH4S0C9Qlwuji65Py43sM3Q'

        # setup the JSON payload for the Google speech-to-text Cloud service
        audio = open(file_path, 'rb')
        config = {
            "config": {
                "encoding": "LINEAR16",
                "languageCode": "en-US"
            },
            "audio": {
                "content": base64.b64encode(audio.read())
            }
        }
        audio.close()

        # make the API call
        r = requests.post('https://speech.googleapis.com/v1/speech:recognize?key={}'.format(API_KEY), json=config)
        self.logger.info(r)
        data = json.loads(r.text)

        # extract and echo the human's speech if status_code=200 (OK)
        if r.status_code == 200:
            text = str(data['results'][0]['alternatives'][0]['transcript'])
            self.tts.say('You said this: {}'.format(text))
            self.outputTranscribedText(text)
        else:
            self.tts.say('I was unable to communicate with Google Cloud services.')

        # stop the program
        self.onStopped()

    def onInput_onStop(self):
        self.onUnload()
        self.onStopped()]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /><Output name="outputTranscribedText" type="3" type_size="1" nature="2" inner="0" tooltip="The transcribed text Pepper received from Google Cloud speech-to-text services." id="5" /></Box><Box name="Google Cloud Integration" id="9" localization="8" tooltip="To comment your behavior. Enter the text here and move the box where you like&#x0A;to add the comment.&#x0A;&#x0A;Note: This box is not functional and has no effect on the behavior." plugin="textedit_plugin" x="851" y="905"><bitmap>media/images/box/box-script.png</bitmap><script language="4"><content><![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("The \"Google Cloud\" Python box handles all requests and responses to the speech-to-text services. It Base64 encodes the temporary audio recording created by the \"Recod Sound\" box (uses its filepath).")]]></content></script><pluginContent><text><![CDATA[The "Google Cloud" Python box handles all requests and responses to the speech-to-text services. It Base64 encodes the temporary audio recording created by the "Recod Sound" box (uses its filepath).]]></text></pluginContent><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" /></Box><Box name="Django LAN" id="10" localization="8" tooltip="MARC: A Python box dedicated to handling requests and responses from the Django web application backend (connected via LAN)." x="1153" y="822"><bitmap>media/images/box/box-python-script.png</bitmap><script language="4"><content><![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.tts = ALProxy('ALTextToSpeech')

    def onLoad(self):
        pass

    def onUnload(self):
        pass

    def onInput_onStart(self):
        self.onInput_inputTranscribedText()

    def onInput_onStop(self):
        self.onUnload()
        self.onStopped()

    def onInput_inputTranscribedText(self, transcribed_text):
        import json
        import requests

        # WARNING: this value will need to change depending on
        # the computer hosting the Django backend
        LAN_HOST = 'http://192.168.254.29:8000'

        # setup the JSON payload
        payload = {
            'active': True,
            'text': transcribed_text,
        }

        # make the API call
        r = requests.post('{}/api/create'.format(LAN_HOST), data=payload)
        self.logger.info(r)
        data = json.loads(r.text)

        # database successfully saved text if status_code=201 (Created)
        if r.status_code == 201:
            id = data['id']
            self.tts.say('Your text was successfully saved as id={}'.format(id))
        else:
            self.logger.warning(data)
            self.tts.say('I was unable to communicate with the Django backend.')

        # stop the program
        self.onStopped()]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Input name="inputTranscribedText" type="3" type_size="1" nature="2" inner="0" tooltip="" id="4" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="5" /></Box><Box name="Django Integration" id="11" localization="8" tooltip="To comment your behavior. Enter the text here and move the box where you like&#x0A;to add the comment.&#x0A;&#x0A;Note: This box is not functional and has no effect on the behavior." plugin="textedit_plugin" x="1112" y="938"><bitmap>media/images/box/box-script.png</bitmap><script language="4"><content><![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("The \"Django LAN\" Python box handles all requests and responses to the Django backend.")]]></content></script><pluginContent><text><![CDATA[The "Django LAN" Python box handles all requests and responses to the Django backend.]]></text></pluginContent><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" /></Box><Box name="Tablet" id="13" localization="8" tooltip="To comment your behavior. Enter the text here and move the box where you like&#x0A;to add the comment.&#x0A;&#x0A;Note: This box is not functional and has no effect on the behavior." plugin="textedit_plugin" x="765" y="83"><bitmap>media/images/box/box-script.png</bitmap><script language="4"><content><![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("This Choregraphe box will show the web assets found in the html directory. The root HTML must be named \"index.html\".")]]></content></script><pluginContent><text><![CDATA[This Choregraphe box will show the web assets found in the html directory. The root HTML must be named "index.html".]]></text></pluginContent><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" /></Box><Box name="Show App" id="14" localization="8" tooltip="Loads the application on the tablet, if it exists, and displays the webview.&#x0A;&#x0A;V1.0.0&#x0A;" x="646" y="125"><bitmap>media/images/box/root.png</bitmap><script language="4"><content><![CDATA[

class MyClass(GeneratedClass):

    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        self.isRunning = False

    def onUnload(self):
        self.isRunning = False

    def _getTabletService(self):
        tabletService = None
        try:
            tabletService = self.session().service("ALTabletService")
        except Exception as e:
            self.logger.error(e)
        return tabletService

    def onInput_onStart(self):
        if self.isRunning:
            return # already running, nothing to do
        self.isRunning = True
        # We create TabletService here in order to avoid
        # problems with connections and disconnections of the tablet during the life of the application
        tabletService = self._getTabletService()
        appName = self.packageUid()
        state = False
        if appName:
            if tabletService:
                if tabletService.loadApplication(appName):
                    self.logger.info("Successfully set application: %s" % appName)
                    tabletService.showWebview()
                    state = True
                else:
                    self.logger.warning("Got tablet service, but failed to set application: %s" % appName)
            else:
                self.logger.warning("Couldn't find tablet service, so can't set application: %s" % appName)
        if state:
            self.onSuccess()
        else:
            self.onFailure()]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Output name="onSuccess" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished successfully." id="3" /><Output name="onFailure" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished unsuccessfully." id="4" /></Box><Link inputowner="1" indexofinput="2" outputowner="2" indexofoutput="3" /><Link inputowner="7" indexofinput="2" outputowner="8" indexofoutput="4" /><Link inputowner="0" indexofinput="4" outputowner="4" indexofoutput="5" /><Link inputowner="8" indexofinput="2" outputowner="4" indexofoutput="6" /><Link inputowner="2" indexofinput="2" outputowner="0" indexofoutput="2" /><Link inputowner="10" indexofinput="4" outputowner="7" indexofoutput="5" /><Link inputowner="4" indexofinput="2" outputowner="1" indexofoutput="3" /><Link inputowner="14" indexofinput="2" outputowner="1" indexofoutput="3" /><Link inputowner="4" indexofinput="4" outputowner="10" indexofoutput="5" /></Diagram></BehaviorKeyframe></BehaviorLayer></Timeline></Box></ChoregrapheProject>